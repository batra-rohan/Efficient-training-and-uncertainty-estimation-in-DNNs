{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h9jZSHYhwmj"
      },
      "source": [
        "# Tutorial notebook\n",
        "\n",
        "This notebook runs the full training pipeline, including:\n",
        "* training the irreducible loss model on the holdout set\n",
        "* training the target model\n",
        "\n",
        "The dataset is CIFAR-10, both target model and irreducible loss model have a Resnet-18 architecture.\n",
        "\n",
        "Note: Before you can run this, you need to install the dependencies and activate the environment (see readme)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/OATML/RHO-Loss.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dFuEnEYD9HI",
        "outputId": "d9f95dea-5555-4ffd-9d3c-b1e721cb27ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'RHO-Loss' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd RHO-Loss/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUhfsMlVyF56",
        "outputId": "4b336307-5ee1-4cf9-9c58-959efc59d88b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RHO-Loss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning\n"
      ],
      "metadata": {
        "id": "N2lKU1X6Irz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f15eb9b-42bb-41a0-f18e-07aa2192e041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.13.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.1.post0 torchmetrics-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCWi3C5Khwmt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BNL(nn.Module):\n",
        "    \"\"\"\n",
        "        Bayesian Normalization Layer (BNL).\n",
        "\n",
        "    This layer replaces traditional normalization layers like BatchNorm,\n",
        "    LayerNorm, and InstanceNorm. It adapts normalization to account for Bayesian\n",
        "    inference, making the model more robust to variations and uncertainties in\n",
        "    the data.\n",
        "\n",
        "    BNL adds gaussian noise during both inference and trainig stages.\n",
        "\n",
        "    This implementation includes parameters named `weight` and `bias` to directly\n",
        "    match those used in PyTorch's BatchNorm, LayerNorm, and InstanceNorm layers\n",
        "    for compatibility when loading state dictionaries.\n",
        "\n",
        "    Args:\n",
        "        num_features (int, list, tuple): Number of features in the input, matches channels\n",
        "                                         in conv layers or features in linear layers. Can\n",
        "                                         be a single integer or a list/tuple for complex scenarios.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features):\n",
        "        super(BNL, self).__init__()\n",
        "        # Check if num_features is a list or tuple, convert if necessary\n",
        "        if isinstance(num_features, int):\n",
        "            num_features = (num_features,)\n",
        "\n",
        "        self.num_features = num_features\n",
        "        self.weight = nn.Parameter(torch.ones(num_features))\n",
        "        self.bias = nn.Parameter(torch.zeros(num_features))\n",
        "        self.eps = 1e-5\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(self.num_features) == 1:  # Traditional usage like BatchNorm\n",
        "            mean = x.mean([0, 2, 3], keepdim=True) if x.dim() == 4 else x.mean(0, keepdim=True)\n",
        "            var = x.var([0, 2, 3], keepdim=True) if x.dim() == 4 else x.var(0, keepdim=True)\n",
        "            x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "            noise = torch.randn(self.weight.shape, device=x.device)\n",
        "            gamma_noisy = self.weight * (1 + noise)\n",
        "\n",
        "            if x.dim() == 4:\n",
        "                gamma_noisy = gamma_noisy.view(1, -1, 1, 1)\n",
        "                bias = self.bias.view(1, -1, 1, 1)\n",
        "            elif x.dim() == 2:\n",
        "                gamma_noisy = gamma_noisy.view(1, -1)\n",
        "                bias = self.bias.view(1, -1)\n",
        "\n",
        "            return gamma_noisy * x_normalized + bias\n",
        "        else:  # LayerNorm-like usage\n",
        "            mean = x.mean(dim=tuple(range(x.dim())[1:]), keepdim=True)\n",
        "            var = x.var(dim=tuple(range(x.dim())[1:]), keepdim=True, unbiased=False)\n",
        "            x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "            noise = torch.randn(self.weight.shape, device=x.device)\n",
        "            gamma_noisy = self.weight * (1 + noise)\n",
        "\n",
        "            weight = self.weight.view((1,) + self.num_features + (1,) * (x.dim() - len(self.num_features) - 1))\n",
        "            bias = self.bias.view((1,) + self.num_features + (1,) * (x.dim() - len(self.num_features) - 1))\n",
        "\n",
        "            return gamma_noisy * x_normalized + bias"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BNLBasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BNLBasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = BNL(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = BNL(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                BNL(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            planes, self.expansion * planes, kernel_size=1, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class BNLResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(BNLResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = BNL(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def BNLResNet18():\n",
        "    return BNLResNet(BNLBasicBlock, [2, 2, 2, 2])"
      ],
      "metadata": {
        "id": "KvkGjsMfh4p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x6qci7rXExce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RHO+ABNN"
      ],
      "metadata": {
        "id": "XEkG-RoNE5M7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_113.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model = BNLResNet18()\n",
        "model.load_state_dict(filtered_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzR8oTOMljAj",
        "outputId": "f352aafd-1012-4bbc-fb36-d0b81f289f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLL without ABNN"
      ],
      "metadata": {
        "id": "4JmttksZhtbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "from torch.nn.functional import softmax\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "RtO61M-3j85L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "0zq7ccq15ymC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_CmOcH4W0bw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4127ab-02b7-4ff2-8de9-ca2777f80842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "all_probs = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)  # logits\n",
        "        probs = torch.softmax(outputs, dim=1)  # convert logits to probabilities\n",
        "\n",
        "        all_probs.append(probs)\n",
        "        true_labels.append(labels)\n",
        "\n",
        "# Concatenate everything\n",
        "all_probs = torch.cat(all_probs, dim=0)            # Shape: [N, C]\n",
        "true_labels = torch.cat(true_labels, dim=0)        # Shape: [N]"
      ],
      "metadata": {
        "id": "TJeRuCPchsVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Use log probabilities for NLL\n",
        "log_probs = torch.log(all_probs + 1e-12)  # for numerical stability\n",
        "\n",
        "# Compute Negative Log-Likelihood\n",
        "nll = F.nll_loss(log_probs, true_labels)\n",
        "print(f\"NLL (Single Model): {nll:.4f}\")"
      ],
      "metadata": {
        "id": "zy68JGnNiOjX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9be78e-da48-45a4-a4ed-42855555e0d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLL (Single Model): 1.7828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwrEK9oEhwmt"
      },
      "outputs": [],
      "source": [
        "class ABNNLoss(torch.nn.Module):\n",
        "    def __init__(self, Num_classes, model_parameters, Weight_decay=1e-4):\n",
        "        super(ABNNLoss, self).__init__()\n",
        "        self.model_parameters = model_parameters\n",
        "        self.Weight_decay = Weight_decay\n",
        "        self.eta = nn.Parameter(torch.ones(Num_classes))\n",
        "\n",
        "    def forward(self, outputs, labels):\n",
        "        # Calculate the three loss components\n",
        "        nll_loss = self.negative_log_likelihood(outputs, labels)\n",
        "        log_prior_loss = self.negative_log_prior(self.model_parameters, self.Weight_decay)\n",
        "        custom_ce_loss = self.custom_cross_entropy_loss(outputs, labels, self.eta)\n",
        "\n",
        "        # Sum up all three components to form the ABNN loss\n",
        "        total_loss = nll_loss + log_prior_loss + custom_ce_loss\n",
        "        return total_loss\n",
        "\n",
        "    @staticmethod\n",
        "    def negative_log_likelihood(outputs, labels):\n",
        "        # Negative Log Likelihood (NLL) or MLE Loss:\n",
        "        # NLL = -∑ log P(y_i | x_i, ω)\n",
        "        return torch.nn.functional.cross_entropy(outputs, labels)\n",
        "\n",
        "    def negative_log_prior(self, model_parameters, Weight_decay=1e-4):\n",
        "        # Negative Log Prior with Gaussian Prior (L2 Regularization):\n",
        "        # log P(ω) = λ ∑ ω^2 where λ (weight decay) = (1/2σ^2)\n",
        "        l2_reg = sum(p.pow(2).sum() for p in model_parameters)\n",
        "        return Weight_decay * l2_reg\n",
        "\n",
        "    def custom_cross_entropy_loss(self, outputs, labels, eta):\n",
        "        # Custom Cross-Entropy Loss:\n",
        "        # E(ω) = -∑ η_i log P(y_i | x_i, ω)\n",
        "        log_probs = torch.nn.functional.log_softmax(outputs, dim=1)\n",
        "        weighted_log_probs = eta[labels] * log_probs.gather(1, labels.unsqueeze(1)).squeeze(1)\n",
        "        return -torch.mean(weighted_log_probs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = ABNNLoss(10, model.parameters()).to(device)\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)\n"
      ],
      "metadata": {
        "id": "EeMrS90Y1UHY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "0ac0a234-2cec-4990-e349-6346a89b642d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f9ed73fdc3bb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mABNNLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0057\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install netcal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PsjiNMWZznQs",
        "outputId": "290e49b5-9625-435a-a986-3b4ae2bb4c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting netcal\n",
            "  Downloading netcal-1.3.6-py3-none-any.whl.metadata (47 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.11/dist-packages (from netcal) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.4 in /usr/local/lib/python3.11/dist-packages (from netcal) (1.15.2)\n",
            "Collecting matplotlib<3.8,>=3.3 (from netcal)\n",
            "  Downloading matplotlib-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.11/dist-packages (from netcal) (1.6.1)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from netcal) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from netcal) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.40 in /usr/local/lib/python3.11/dist-packages (from netcal) (4.67.1)\n",
            "Collecting pyro-ppl>=1.8 (from netcal)\n",
            "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting tikzplotlib==0.9.8 (from netcal)\n",
            "  Downloading tikzplotlib-0.9.8-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: tensorboard>=2.2 in /usr/local/lib/python3.11/dist-packages (from netcal) (2.18.0)\n",
            "Collecting gpytorch>=1.5.1 (from netcal)\n",
            "  Downloading gpytorch-1.14-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from tikzplotlib==0.9.8->netcal) (11.2.1)\n",
            "Collecting jaxtyping (from gpytorch>=1.5.1->netcal)\n",
            "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch>=1.5.1->netcal) (1.3.0)\n",
            "Collecting linear-operator>=0.6 (from gpytorch>=1.5.1->netcal)\n",
            "  Downloading linear_operator-0.6-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8,>=3.3->netcal) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8,>=3.3->netcal) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8,>=3.3->netcal) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8,>=3.3->netcal) (1.4.8)\n",
            "Collecting numpy>=1.18 (from netcal)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8,>=3.3->netcal) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8,>=3.3->netcal) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.8,>=3.3->netcal) (2.9.0.post0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8->netcal) (3.4.0)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.8->netcal)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24->netcal) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24->netcal) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2->netcal) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2->netcal) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2->netcal) (3.8)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2->netcal) (5.29.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2->netcal) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2->netcal) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2->netcal) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.2->netcal) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->netcal) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->netcal) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->netcal) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->netcal) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->netcal) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9->netcal)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9->netcal)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9->netcal)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->netcal)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->netcal)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->netcal)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->netcal)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->netcal)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->netcal)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->netcal) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->netcal) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->netcal) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->netcal)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->netcal) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->netcal) (1.13.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2->netcal) (3.0.2)\n",
            "Collecting wadler-lindig>=0.1.3 (from jaxtyping->gpytorch>=1.5.1->netcal)\n",
            "  Downloading wadler_lindig-0.1.5-py3-none-any.whl.metadata (17 kB)\n",
            "Downloading netcal-1.3.6-py3-none-any.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.3/236.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tikzplotlib-0.9.8-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gpytorch-1.14-py3-none-any.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.7/277.7 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m124.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading linear_operator-0.6-py3-none-any.whl (176 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.3/176.3 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Downloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wadler_lindig-0.1.5-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: pyro-api, wadler-lindig, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, nvidia-cusolver-cu12, matplotlib, tikzplotlib, pyro-ppl, linear-operator, gpytorch, netcal\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gpytorch-1.14 jaxtyping-0.3.2 linear-operator-0.6 matplotlib-3.7.5 netcal-1.3.6 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyro-api-0.1.2 pyro-ppl-1.9.1 tikzplotlib-0.9.8 wadler-lindig-0.1.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "886afb240e7741aabcf67d706f91cda6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import netcal.metrics as metrics\n",
        "from netcal.metrics import ECE\n",
        "from sklearn.metrics import precision_recall_curve, auc, roc_auc_score, roc_curve"
      ],
      "metadata": {
        "id": "KQpc5KVEzhmf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "16ed2758-87c1-4e07-e417-63ae149c5e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy.rec'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f6f760abace2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetcal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnetcal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mECE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/netcal/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.3.6'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mAbstractCalibration\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAbstractCalibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mDecorator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccepts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_accepts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mContext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmanual_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/netcal/AbstractCalibration.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformerMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0m_distributor_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m  \u001b[0;31m# noqa: E402\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_parameter_constraints\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata_routing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_bunch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_chunking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_chunking.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_param_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from ._sputils import (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[0m\u001b[1;32m      6\u001b[0m                        \u001b[0mget_sum_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misdense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                        matrix, validateaxis, getdtype)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/sparse/_sputils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnp_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp_ulong\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_namespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_numpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_docscrape\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctionDoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_api_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m from scipy._lib.array_api_compat import (\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mis_array_api_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxp_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/_lib/array_api_compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from numpy import * doesn't overwrite these builtin names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfloat32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.rec'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf data"
      ],
      "metadata": {
        "id": "skYP7Xn_5Hti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall numpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4qF8iX8HZRc",
        "outputId": "926200f7-3226-4651-a98a-9b0a78f1b1f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "matplotlib 3.7.5 requires numpy<2,>=1.20, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n",
            "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('Start Training')\n",
        "\n",
        "# Timing the training process\n",
        "start_time = time.time()\n",
        "\n",
        "# List to store loss values\n",
        "train_losses = []\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        eta = torch.rand(labels.size(0), device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "    print(f'[Epoch {epoch + 1}, Loss: {running_loss}')\n",
        "    running_loss = 0.0\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print('Finished Training')\n",
        "print(f'Time taken to train the model: {end_time - start_time:.2f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWi0pBQvzQl1",
        "outputId": "0693b0d1-f1a1-456d-94d3-aa29505149f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training\n",
            "[Epoch 1, Loss: 862.4734661579132\n",
            "[Epoch 2, Loss: 657.6451494693756\n",
            "[Epoch 3, Loss: 619.3060858249664\n",
            "[Epoch 4, Loss: 579.5586772561073\n",
            "[Epoch 5, Loss: 568.1233695745468\n",
            "[Epoch 6, Loss: 540.1672561168671\n",
            "[Epoch 7, Loss: 525.1075974702835\n",
            "[Epoch 8, Loss: 503.56338477134705\n",
            "[Epoch 9, Loss: 498.4417510032654\n",
            "[Epoch 10, Loss: 496.62491196393967\n",
            "[Epoch 11, Loss: 483.50263118743896\n",
            "[Epoch 12, Loss: 473.1645570397377\n",
            "[Epoch 13, Loss: 469.17793464660645\n",
            "[Epoch 14, Loss: 456.07257401943207\n",
            "[Epoch 15, Loss: 451.30593103170395\n",
            "[Epoch 16, Loss: 451.98159915208817\n",
            "[Epoch 17, Loss: 443.9652162194252\n",
            "[Epoch 18, Loss: 438.64993929862976\n",
            "[Epoch 19, Loss: 433.2899259328842\n",
            "[Epoch 20, Loss: 431.78097385168076\n",
            "Finished Training\n",
            "Time taken to train the model: 1226.16 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/OATML/RHO-Loss.git"
      ],
      "metadata": {
        "id": "NZ0BgzUZt26R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd RHO-Loss/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxma6f6Du_kY",
        "outputId": "8364a53d-3098-41c3-90c2-69fca12e0f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RHO-Loss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the training loss\n",
        "plt.figure()\n",
        "plt.plot(train_losses)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S-E_HusPvKsl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "98bc1f45-b577-4ff4-efec-2a759323b8f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0DRRgIPr-sw",
        "outputId": "d60e578a-c47c-4649-ed69-40532766318d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 87.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': running_loss,\n",
        "}, 'rhoabnn.ckpt')\n"
      ],
      "metadata": {
        "id": "n9SU1q1csQ4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluationg Resnet with rho loss"
      ],
      "metadata": {
        "id": "ZAMJ71L51vRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_113.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "#filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model1 = ResNet18()\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "model1.to(device)\n",
        "model1.load_state_dict(new_state_dict)\n",
        "\n",
        "# Set to eval mode (optional)\n",
        "model1.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkrjIXk7uCLc",
        "outputId": "7c2df44f-9185-44c1-a780-fe8dc8605bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5VCmcepkuq9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h8tsTsTf1tGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            planes, self.expansion * planes, kernel_size=1, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n",
        "\n",
        "\n",
        "def resnet18_imagenet(pretrained=False, classes=10):\n",
        "    model = torchvision.models.resnet18(pretrained=pretrained, num_classes=1000)\n",
        "    model.conv1 = nn.Conv2d(\n",
        "        3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
        "    )\n",
        "    model.maxpool = nn.Identity()\n",
        "    model.fc = nn.Linear(512, classes, bias=True)\n",
        "    return model\n",
        "\n",
        "def resnet50_imagenet(pretrained=False, classes=10):\n",
        "    model = torchvision.models.resnet50(pretrained=pretrained, num_classes=1000)\n",
        "    model.fc = nn.Linear(512, classes, bias=True)\n",
        "    return model"
      ],
      "metadata": {
        "id": "vcs8LmZPwiNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "model1.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = model1(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iGD7r3owyyu",
        "outputId": "79818398-3d35-4637-b51d-12f552a69863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 89.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training ABNN for resnet without rho loss\n"
      ],
      "metadata": {
        "id": "jT6UHbGQ1mhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_142.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model2 = BNLResNet18()\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "model2.to(device)\n",
        "model2.load_state_dict(filtered_state_dict)\n",
        "\n",
        "# Set to eval mode (optional)\n",
        "model2.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF5khL_6y__C",
        "outputId": "58686228-6eab-46ee-aed5-dc288455e6c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BNLResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BNL()\n",
              "  (layer1): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BNL()\n",
              "      )\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BNL()\n",
              "      )\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BNL()\n",
              "      )\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = ABNNLoss(10, model.parameters()).to(device)\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)\n"
      ],
      "metadata": {
        "id": "8bIdfEIB4liI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('Start Training')\n",
        "\n",
        "# Timing the training process\n",
        "start_time = time.time()\n",
        "\n",
        "# List to store loss values\n",
        "train_losses = []\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        eta = torch.rand(labels.size(0), device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model2(inputs)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "    print(f'[Epoch {epoch + 1}, Loss: {running_loss}')\n",
        "    running_loss = 0.0\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print('Finished Training')\n",
        "print(f'Time taken to train the model: {end_time - start_time:.2f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdxnpqKO2czQ",
        "outputId": "648a144e-b9a6-42b1-c035-0143d3319cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training\n",
            "[Epoch 1, Loss: 808.6131503582001\n",
            "[Epoch 2, Loss: 626.1823525428772\n",
            "[Epoch 3, Loss: 591.6339709758759\n",
            "[Epoch 4, Loss: 566.3530452847481\n",
            "[Epoch 5, Loss: 549.651691198349\n",
            "[Epoch 6, Loss: 533.3991477489471\n",
            "[Epoch 7, Loss: 522.094912648201\n",
            "[Epoch 8, Loss: 522.9564603567123\n",
            "[Epoch 9, Loss: 506.3806129693985\n",
            "[Epoch 10, Loss: 509.3108307123184\n",
            "[Epoch 11, Loss: 496.49385553598404\n",
            "[Epoch 12, Loss: 492.7394669055939\n",
            "[Epoch 13, Loss: 485.9119859933853\n",
            "[Epoch 14, Loss: 480.14716923236847\n",
            "[Epoch 15, Loss: 475.07631528377533\n",
            "[Epoch 16, Loss: 471.64194172620773\n",
            "[Epoch 17, Loss: 464.5568643808365\n",
            "[Epoch 18, Loss: 463.2601583600044\n",
            "[Epoch 19, Loss: 459.07375156879425\n",
            "[Epoch 20, Loss: 456.3744861483574\n",
            "Finished Training\n",
            "Time taken to train the model: 1199.59 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "model2.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = model2(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfzgIuDc2ckp",
        "outputId": "761db2d2-b8cf-44bd-8f64-df25d0353aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 85.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model2.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': running_loss,\n",
        "}, 'resnetabnn.ckpt')"
      ],
      "metadata": {
        "id": "zH_0oVPG5YBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zBTLd3td2che"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluaing restnet without rho loss"
      ],
      "metadata": {
        "id": "TFqGIzLG2dZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy matplotlib torch torchvision pytorch-lightning torchmetrics plotnine\n",
        "!pip install numpy==1.24.4 matplotlib==3.8.2 torch torchvision pytorch-lightning==2.1.3 torchmetrics plotnine\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8L47yd46JOW4",
        "outputId": "e3810d69-6dad-4cbe-a7b4-8560fff46fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.2.5\n",
            "Uninstalling numpy-2.2.5:\n",
            "  Successfully uninstalled numpy-2.2.5\n",
            "Found existing installation: matplotlib 3.7.5\n",
            "Uninstalling matplotlib-3.7.5:\n",
            "  Successfully uninstalled matplotlib-3.7.5\n",
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: pytorch-lightning 2.5.1.post0\n",
            "Uninstalling pytorch-lightning-2.5.1.post0:\n",
            "  Successfully uninstalled pytorch-lightning-2.5.1.post0\n",
            "Found existing installation: torchmetrics 1.7.1\n",
            "Uninstalling torchmetrics-1.7.1:\n",
            "  Successfully uninstalled torchmetrics-1.7.1\n",
            "Found existing installation: plotnine 0.14.5\n",
            "Uninstalling plotnine-0.14.5:\n",
            "  Successfully uninstalled plotnine-0.14.5\n",
            "Collecting numpy==1.24.4\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting matplotlib==3.8.2\n",
            "  Downloading matplotlib-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting torch\n",
            "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting pytorch-lightning==2.1.3\n",
            "  Downloading pytorch_lightning-2.1.3-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchmetrics\n",
            "  Using cached torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting plotnine\n",
            "  Downloading plotnine-0.14.5-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.2) (2.9.0.post0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.3) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.3) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.3) (4.13.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning==2.1.3) (0.14.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch)\n",
            "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch) (75.2.0)\n",
            "Requirement already satisfied: pandas>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from plotnine) (2.2.2)\n",
            "Requirement already satisfied: mizani~=0.13.0 in /usr/local/lib/python3.11/dist-packages (from plotnine) (0.13.3)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from plotnine) (1.15.2)\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from plotnine) (0.14.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3) (3.11.15)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->plotnine) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.2.0->plotnine) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.2) (1.17.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.14.0->plotnine) (1.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3) (1.20.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning==2.1.3) (3.10)\n",
            "Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.1.3-py3-none-any.whl (777 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.7/777.7 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "Downloading plotnine-0.14.5-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, matplotlib, torch, plotnine, torchvision, torchmetrics, pytorch-lightning\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.5.147\n",
            "    Uninstalling nvidia-curand-cu12-10.3.5.147:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.5.147\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.4.5.8\n",
            "    Uninstalling nvidia-cublas-cu12-12.4.5.8:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.3.1.170\n",
            "    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.1.3\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.1.3:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.1.9:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "netcal 1.3.6 requires matplotlib<3.8,>=3.3, but you have matplotlib 3.8.2 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.22.0 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "blosc2 3.3.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.8.2 numpy-1.24.4 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 plotnine-0.14.5 pytorch-lightning-2.1.3 sympy-1.14.0 torch-2.7.0 torchmetrics-1.7.1 torchvision-0.22.0 triton-3.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "lightning_fabric",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "sympy",
                  "torch",
                  "torchgen",
                  "torchvision",
                  "triton"
                ]
              },
              "id": "c9ac764eba134be59c2a437e2b830c8a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd RHO-Loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-svM_xYIXH_",
        "outputId": "655ebd7d-f75b-49b5-d3b3-79c0d4c3deb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RHO-Loss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning import LightningModule\n",
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_142.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "#filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model4 = ResNet18()\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "model4.to(device)\n",
        "model4.load_state_dict(new_state_dict)\n",
        "\n",
        "# Set to eval mode (optional)\n",
        "model4.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO9LNd742hA-",
        "outputId": "13ffa3b7-cb68-437d-f1da-a33625666304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "model4.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = model4(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyy4qYdpLAYb",
        "outputId": "6f09e0bd-2428-4ef4-cdc1-ed9766d45b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 85.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5wT9EU4GIV37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple ABNN instances"
      ],
      "metadata": {
        "id": "ZFBh2IwFKHov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to set seeds for reproducibility\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "# Train one instance of the model\n",
        "def train_one_instance(model_id, trainloader, device, loss_func, num_epochs=20):\n",
        "    print(f\"Training model {model_id}\")\n",
        "\n",
        "    set_seed(42 + model_id)  # Different seed for each instance\n",
        "\n",
        "    model = BNLResNet18().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    model.train()\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            eta = torch.rand(labels.size(0), device=device)  # Unused here?\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        print(f'[Model {model_id}, Epoch {epoch + 1}] Loss: {running_loss:.4f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f'Model {model_id} Finished Training in {end_time - start_time:.2f} seconds')\n",
        "\n",
        "    # Save the model\n",
        "    torch.save(model.state_dict(), f\"bnlresnet18_instance_{model_id}.pth\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "zsf_zOKIKHW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble_predict(models, dataloader, device):\n",
        "    all_outputs = []\n",
        "\n",
        "    for model in models:\n",
        "        model.eval()\n",
        "        outputs = []\n",
        "        with torch.no_grad():\n",
        "            for data in dataloader:\n",
        "                inputs, _ = data\n",
        "                inputs = inputs.to(device)\n",
        "                output = torch.softmax(model(inputs), dim=1)  # probability outputs\n",
        "                outputs.append(output.cpu())\n",
        "        all_outputs.append(torch.cat(outputs))\n",
        "\n",
        "    # Average predictions\n",
        "    ensemble_output = torch.mean(torch.stack(all_outputs), dim=0)\n",
        "    return ensemble_output"
      ],
      "metadata": {
        "id": "zgBMGwEhKJyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = ABNNLoss(10, model.parameters()).to(device)\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)\n"
      ],
      "metadata": {
        "id": "92iUWxU0Kk_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train 4 instances\n",
        "models = []\n",
        "for i in range(4):\n",
        "    model = train_one_instance(i, trainloader, device, loss_func)\n",
        "    models.append(model)\n",
        "\n",
        "# Perform ensemble inference\n",
        "ensemble_probs = ensemble_predict(models, testloader, device)\n",
        "\n",
        "# If you want hard labels:\n",
        "ensemble_preds = torch.argmax(ensemble_probs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zctyIal8KQCU",
        "outputId": "b9babdd8-cb8d-413f-a259-31a23fe4ab63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model 0\n",
            "[Model 0, Epoch 1] Loss: 1481.0283\n",
            "[Model 0, Epoch 2] Loss: 1217.8668\n",
            "[Model 0, Epoch 3] Loss: 1094.2764\n",
            "[Model 0, Epoch 4] Loss: 980.1893\n",
            "[Model 0, Epoch 5] Loss: 872.5084\n",
            "[Model 0, Epoch 6] Loss: 794.0697\n",
            "[Model 0, Epoch 7] Loss: 735.5834\n",
            "[Model 0, Epoch 8] Loss: 687.5649\n",
            "[Model 0, Epoch 9] Loss: 639.6671\n",
            "[Model 0, Epoch 10] Loss: 600.2663\n",
            "[Model 0, Epoch 11] Loss: 579.2804\n",
            "[Model 0, Epoch 12] Loss: 553.8263\n",
            "[Model 0, Epoch 13] Loss: 526.9241\n",
            "[Model 0, Epoch 14] Loss: 505.1476\n",
            "[Model 0, Epoch 15] Loss: 495.4999\n",
            "[Model 0, Epoch 16] Loss: 476.8181\n",
            "[Model 0, Epoch 17] Loss: 465.6735\n",
            "[Model 0, Epoch 18] Loss: 446.4739\n",
            "[Model 0, Epoch 19] Loss: 434.7401\n",
            "[Model 0, Epoch 20] Loss: 428.5114\n",
            "Model 0 Finished Training in 1272.23 seconds\n",
            "Training model 1\n",
            "[Model 1, Epoch 1] Loss: 1462.9839\n",
            "[Model 1, Epoch 2] Loss: 1217.3644\n",
            "[Model 1, Epoch 3] Loss: 1088.3284\n",
            "[Model 1, Epoch 4] Loss: 966.7893\n",
            "[Model 1, Epoch 5] Loss: 866.1179\n",
            "[Model 1, Epoch 6] Loss: 788.1896\n",
            "[Model 1, Epoch 7] Loss: 730.5836\n",
            "[Model 1, Epoch 8] Loss: 678.1946\n",
            "[Model 1, Epoch 9] Loss: 636.0836\n",
            "[Model 1, Epoch 10] Loss: 602.6303\n",
            "[Model 1, Epoch 11] Loss: 574.9835\n",
            "[Model 1, Epoch 12] Loss: 551.0633\n",
            "[Model 1, Epoch 13] Loss: 532.8125\n",
            "[Model 1, Epoch 14] Loss: 508.8529\n",
            "[Model 1, Epoch 15] Loss: 495.5443\n",
            "[Model 1, Epoch 16] Loss: 478.6615\n",
            "[Model 1, Epoch 17] Loss: 465.8941\n",
            "[Model 1, Epoch 18] Loss: 455.5900\n",
            "[Model 1, Epoch 19] Loss: 441.5257\n",
            "[Model 1, Epoch 20] Loss: 434.0224\n",
            "Model 1 Finished Training in 1275.09 seconds\n",
            "Training model 2\n",
            "[Model 2, Epoch 1] Loss: 1470.9014\n",
            "[Model 2, Epoch 2] Loss: 1225.6797\n",
            "[Model 2, Epoch 3] Loss: 1090.7510\n",
            "[Model 2, Epoch 4] Loss: 976.8687\n",
            "[Model 2, Epoch 5] Loss: 882.9564\n",
            "[Model 2, Epoch 6] Loss: 799.5308\n",
            "[Model 2, Epoch 7] Loss: 743.1045\n",
            "[Model 2, Epoch 8] Loss: 691.0368\n",
            "[Model 2, Epoch 9] Loss: 649.3069\n",
            "[Model 2, Epoch 10] Loss: 610.3980\n",
            "[Model 2, Epoch 11] Loss: 586.2004\n",
            "[Model 2, Epoch 12] Loss: 559.0450\n",
            "[Model 2, Epoch 13] Loss: 536.3143\n",
            "[Model 2, Epoch 14] Loss: 515.9042\n",
            "[Model 2, Epoch 15] Loss: 498.5236\n",
            "[Model 2, Epoch 16] Loss: 481.0782\n",
            "[Model 2, Epoch 17] Loss: 466.7348\n",
            "[Model 2, Epoch 18] Loss: 450.6960\n",
            "[Model 2, Epoch 19] Loss: 441.5627\n",
            "[Model 2, Epoch 20] Loss: 428.9868\n",
            "Model 2 Finished Training in 1274.89 seconds\n",
            "Training model 3\n",
            "[Model 3, Epoch 1] Loss: 1488.3493\n",
            "[Model 3, Epoch 2] Loss: 1225.0644\n",
            "[Model 3, Epoch 3] Loss: 1101.1199\n",
            "[Model 3, Epoch 4] Loss: 981.5759\n",
            "[Model 3, Epoch 5] Loss: 891.3036\n",
            "[Model 3, Epoch 6] Loss: 810.2941\n",
            "[Model 3, Epoch 7] Loss: 749.7720\n",
            "[Model 3, Epoch 8] Loss: 695.8058\n",
            "[Model 3, Epoch 9] Loss: 656.0187\n",
            "[Model 3, Epoch 10] Loss: 612.3611\n",
            "[Model 3, Epoch 11] Loss: 588.9673\n",
            "[Model 3, Epoch 12] Loss: 560.1624\n",
            "[Model 3, Epoch 13] Loss: 537.7491\n",
            "[Model 3, Epoch 14] Loss: 520.0848\n",
            "[Model 3, Epoch 15] Loss: 500.3183\n",
            "[Model 3, Epoch 16] Loss: 480.9929\n",
            "[Model 3, Epoch 17] Loss: 471.8931\n",
            "[Model 3, Epoch 18] Loss: 460.4783\n",
            "[Model 3, Epoch 19] Loss: 442.6814\n",
            "[Model 3, Epoch 20] Loss: 435.2329\n",
            "Model 3 Finished Training in 1273.49 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_NLL(probs, labels):\n",
        "    \"\"\"\n",
        "    probs: tensor of shape (N, C) - ensemble probabilities (after softmax and averaging)\n",
        "    labels: tensor of shape (N,) - ground truth labels\n",
        "    \"\"\"\n",
        "    # Use log probabilities and gather only for correct classes\n",
        "    log_probs = torch.log(probs + 1e-12)  # avoid log(0)\n",
        "    nll = F.nll_loss(log_probs, labels, reduction='mean')\n",
        "    return nll.item()"
      ],
      "metadata": {
        "id": "wl5-Spt1KP1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get true labels from testloader\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        true_labels.extend(labels)\n",
        "\n",
        "# Convert to a torch tensor\n",
        "true_labels = torch.tensor(true_labels, dtype=torch.long, device=ensemble_probs.device)"
      ],
      "metadata": {
        "id": "MWeKLsUVK-oM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "bf6e1dad-af17-4193-e346-945550552dfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'ensemble_probs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-24cadd76114c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Convert to a torch tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrue_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensemble_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ensemble_probs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `ensemble_probs` is of shape [N, C] and already averaged over ensemble members\n",
        "# And `true_labels` is a 1D tensor of length N\n",
        "\n",
        "nll = compute_NLL(ensemble_probs, true_labels)\n",
        "print(f\"NLL (Ensemble): {nll:.4f}\")"
      ],
      "metadata": {
        "id": "RT3GsoPdKVWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b4e918-9b9a-47fe-c8b1-bc343442e725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLL (Ensemble): 0.5193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rNOD84E-KVOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "apXeA1fbQl7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            planes, self.expansion * planes, kernel_size=1, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=100):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n",
        "\n",
        "\n",
        "def resnet18_imagenet(pretrained=False, classes=10):\n",
        "    model = torchvision.models.resnet18(pretrained=pretrained, num_classes=1000)\n",
        "    model.conv1 = nn.Conv2d(\n",
        "        3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
        "    )\n",
        "    model.maxpool = nn.Identity()\n",
        "    model.fc = nn.Linear(512, classes, bias=True)\n",
        "    return model\n",
        "\n",
        "def resnet50_imagenet(pretrained=False, classes=10):\n",
        "    model = torchvision.models.resnet50(pretrained=pretrained, num_classes=1000)\n",
        "    model.fc = nn.Linear(512, classes, bias=True)\n",
        "    return model"
      ],
      "metadata": {
        "id": "CAGS850TX0Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BNLBasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BNLBasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = BNL(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = BNL(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                BNL(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            planes, self.expansion * planes, kernel_size=1, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class BNLResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=100):\n",
        "        super(BNLResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = BNL(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def BNLResNet18():\n",
        "    return BNLResNet(BNLBasicBlock, [2, 2, 2, 2])"
      ],
      "metadata": {
        "id": "f6GRnFa4QlxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESNET 18 CIFAR 100 WITHOUT RHO LOSS ABNN\n"
      ],
      "metadata": {
        "id": "TJ_DXnluRk0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_167.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model5 = BNLResNet18()\n",
        "model5.load_state_dict(filtered_state_dict)"
      ],
      "metadata": {
        "id": "og7VXnJuKU6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66320c28-7103-4aa9-c06c-55820c7a6469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "model5.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "me0Cxn1IRHqO",
        "outputId": "19c22907-c17a-4064-a499-79b993e90bd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BNLResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BNL()\n",
              "  (layer1): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BNL()\n",
              "      )\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BNL()\n",
              "      )\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BNL()\n",
              "      )\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = ABNNLoss(10, model5.parameters()).to(device)\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model5.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "upvRaCymRU36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('Start Training')\n",
        "\n",
        "# Timing the training process\n",
        "start_time = time.time()\n",
        "\n",
        "# List to store loss values\n",
        "train_losses = []\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        eta = torch.rand(labels.size(0), device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model5(inputs)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "    print(f'[Epoch {epoch + 1}, Loss: {running_loss}')\n",
        "    running_loss = 0.0\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print('Finished Training')\n",
        "print(f'Time taken to train the model: {end_time - start_time:.2f} seconds')"
      ],
      "metadata": {
        "id": "-LlGnOf-vuSk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "55d33625-23f6-41fe-f8de-7ab163af0823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-b218357f1008>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "model5.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = model5(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4A0Zo_QN_Qp",
        "outputId": "b4913e5e-13fa-4a37-b124-b44dea5d5855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 75.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.eval()\n",
        "all_probs = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model5(inputs)  # logits\n",
        "        probs = torch.softmax(outputs, dim=1)  # convert logits to probabilities\n",
        "\n",
        "        all_probs.append(probs)\n",
        "        true_labels.append(labels)\n",
        "\n",
        "# Concatenate everything\n",
        "all_probs = torch.cat(all_probs, dim=0)            # Shape: [N, C]\n",
        "true_labels = torch.cat(true_labels, dim=0)"
      ],
      "metadata": {
        "id": "UjtZoLh0RZft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Use log probabilities for NLL\n",
        "log_probs = torch.log(all_probs + 1e-12)  # for numerical stability\n",
        "\n",
        "# Compute Negative Log-Likelihood\n",
        "nll = F.nll_loss(log_probs, true_labels)\n",
        "print(f\"NLL (Single Model): {nll:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgQnEmlNR_Uu",
        "outputId": "064f5997-6438-44e3-ec9a-8e96dbd71902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLL (Single Model): 0.9401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model5.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': running_loss,\n",
        "}, 'bnn100.ckpt')"
      ],
      "metadata": {
        "id": "Q-B5KTrQSOYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR100 RESNET 18 WITHOUT RHO LOSS"
      ],
      "metadata": {
        "id": "7couYv5rSgnI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_167.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "#filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model6 = ResNet18()\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "model6.to(device)\n",
        "model6.load_state_dict(new_state_dict)\n",
        "\n",
        "# Set to eval mode (optional)\n",
        "model6.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh0ENPoSSDH6",
        "outputId": "e014b421-0b81-42e4-d8f2-8caac57ca453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "model6.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = model6(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_IXb5F9SxFb",
        "outputId": "d839d740-ae4a-4cc4-e8f9-7f050f815a0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 56.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.eval()\n",
        "all_probs = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model6(inputs)  # logits\n",
        "        probs = torch.softmax(outputs, dim=1)  # convert logits to probabilities\n",
        "\n",
        "        all_probs.append(probs)\n",
        "        true_labels.append(labels)\n",
        "\n",
        "# Concatenate everything\n",
        "all_probs = torch.cat(all_probs, dim=0)            # Shape: [N, C]\n",
        "true_labels = torch.cat(true_labels, dim=0)"
      ],
      "metadata": {
        "id": "GrxwteqyS2ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Use log probabilities for NLL\n",
        "log_probs = torch.log(all_probs + 1e-12)  # for numerical stability\n",
        "\n",
        "# Compute Negative Log-Likelihood\n",
        "nll = F.nll_loss(log_probs, true_labels)\n",
        "print(f\"NLL (Single Model): {nll:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRlrMU_bS7O1",
        "outputId": "e6b6f032-cefe-4935-8d16-3ac410404170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLL (Single Model): 1.8022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kJUDqRt9S_kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6v90KKi3S_Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CIFAR 100 WITH RHO LOSS ABNN"
      ],
      "metadata": {
        "id": "hZkkkurBX8vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_173.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model7 = BNLResNet18()\n",
        "model7.load_state_dict(filtered_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3kbJfv0YRpA",
        "outputId": "ba65f3f1-b18b-4443-f752-563a5b413256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7.to(device)\n",
        "loss_func = ABNNLoss(10, model7.parameters()).to(device)\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model7.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "tpTGmC3jYjl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('Start Training')\n",
        "\n",
        "# Timing the training process\n",
        "start_time = time.time()\n",
        "\n",
        "# List to store loss values\n",
        "train_losses = []\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        eta = torch.rand(labels.size(0), device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model7(inputs)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "    print(f'[Epoch {epoch + 1}, Loss: {running_loss}')\n",
        "    running_loss = 0.0\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print('Finished Training')\n",
        "print(f'Time taken to train the model: {end_time - start_time:.2f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "cNEeoN6zYjiY",
        "outputId": "22d3f73a-df76-4828-d756-4572d637e13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-78b861d20a73>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel7\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-aaef5be45caf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, outputs, labels)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnll_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlog_prior_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcustom_ce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_cross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Sum up all three components to form the ABNN loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-aaef5be45caf>\u001b[0m in \u001b[0;36mcustom_cross_entropy_loss\u001b[0;34m(self, outputs, labels, eta)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# E(ω) = -∑ η_i log P(y_i | x_i, ω)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mlog_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mweighted_log_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweighted_log_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "model7.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = model7(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqgVCbx2Yjfr",
        "outputId": "2287e009-7019-4ead-fe1f-2f678833ff6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 66.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7.eval()\n",
        "all_probs = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model7(inputs)  # logits\n",
        "        probs = torch.softmax(outputs, dim=1)  # convert logits to probabilities\n",
        "\n",
        "        all_probs.append(probs)\n",
        "        true_labels.append(labels)\n",
        "\n",
        "# Concatenate everything\n",
        "all_probs = torch.cat(all_probs, dim=0)            # Shape: [N, C]\n",
        "true_labels = torch.cat(true_labels, dim=0)"
      ],
      "metadata": {
        "id": "EKmgmAy3Yjcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Use log probabilities for NLL\n",
        "log_probs = torch.log(all_probs + 1e-12)  # for numerical stability\n",
        "\n",
        "# Compute Negative Log-Likelihood\n",
        "nll = F.nll_loss(log_probs, true_labels)\n",
        "print(f\"NLL (Single Model): {nll:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgDD6CmpYjaF",
        "outputId": "f3896486-bff8-42d2-b9f6-a143a930fd8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLL (Single Model): 1.1147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model7.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': running_loss,\n",
        "}, 'rhoabnn100.ckpt')"
      ],
      "metadata": {
        "id": "yBpIn-4MYjXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "with rho loss, cifar 100"
      ],
      "metadata": {
        "id": "WOKG_inMaQg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_173.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "#filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model8 = ResNet18()\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "model8.to(device)\n",
        "model8.load_state_dict(new_state_dict)\n",
        "\n",
        "# Set to eval mode (optional)\n",
        "model8.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2FfNSpOYjQr",
        "outputId": "482f0e1f-080a-49de-a61f-1efa40d15d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = ABNNLoss(100, model8.parameters()).to(device)\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model7.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "pvBWDdZJPow-",
        "outputId": "8721c59c-d485-4517-de37-fb71264b2589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-d20fdb66c265>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mABNNLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel7\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0057\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1341\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1327\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     )\n\u001b[0;32m-> 1329\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1330\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "model8.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = model8(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46M_IbwZYjG7",
        "outputId": "84971583-a7b2-4ef8-84b0-5af730eeb7aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 33.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model8.eval()\n",
        "all_probs = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model8(inputs)  # logits\n",
        "        probs = torch.softmax(outputs, dim=1)  # convert logits to probabilities\n",
        "\n",
        "        all_probs.append(probs)\n",
        "        true_labels.append(labels)\n",
        "\n",
        "# Concatenate everything\n",
        "all_probs = torch.cat(all_probs, dim=0)            # Shape: [N, C]\n",
        "true_labels = torch.cat(true_labels, dim=0)"
      ],
      "metadata": {
        "id": "dZx91HWAanbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Use log probabilities for NLL\n",
        "log_probs = torch.log(all_probs + 1e-12)  # for numerical stability\n",
        "\n",
        "# Compute Negative Log-Likelihood\n",
        "nll = F.nll_loss(log_probs, true_labels)\n",
        "print(f\"NLL (Single Model): {nll:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k09b-Dv4ar2l",
        "outputId": "3244d34e-ebb1-42f3-d278-8a36b37bc4b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLL (Single Model): 6.5717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RqiStmG2a16N"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}