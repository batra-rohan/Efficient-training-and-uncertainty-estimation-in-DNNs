{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F5Ap8NsPMnk",
        "outputId": "37a24e2b-9d56-4d66-b278-a0fe48fa34ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RHO-Loss'...\n",
            "remote: Enumerating objects: 449, done.\u001b[K\n",
            "remote: Counting objects: 100% (449/449), done.\u001b[K\n",
            "remote: Compressing objects: 100% (271/271), done.\u001b[K\n",
            "remote: Total 449 (delta 187), reused 411 (delta 162), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (449/449), 267.26 KiB | 2.75 MiB/s, done.\n",
            "Resolving deltas: 100% (187/187), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/OATML/RHO-Loss.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "from torch.nn.functional import softmax\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "gLUXgeUqPz7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_5odiX0PNQv",
        "outputId": "45cb8537-021d-43a7-87bf-a1dc2635ec84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (2.5.1.post0)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (1.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (4.13.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning) (0.14.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd RHO-Loss/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saoGT_ujPPT5",
        "outputId": "7bc82b4f-870b-4554-a1ab-ff6c95c79fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RHO-Loss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.RandomHorizontalFlip(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "Egqw_BG5P4O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class BNL(nn.Module):\n",
        "    \"\"\"\n",
        "        Bayesian Normalization Layer (BNL).\n",
        "\n",
        "    This layer replaces traditional normalization layers like BatchNorm,\n",
        "    LayerNorm, and InstanceNorm. It adapts normalization to account for Bayesian\n",
        "    inference, making the model more robust to variations and uncertainties in\n",
        "    the data.\n",
        "\n",
        "    BNL adds gaussian noise during both inference and trainig stages.\n",
        "\n",
        "    This implementation includes parameters named `weight` and `bias` to directly\n",
        "    match those used in PyTorch's BatchNorm, LayerNorm, and InstanceNorm layers\n",
        "    for compatibility when loading state dictionaries.\n",
        "\n",
        "    Args:\n",
        "        num_features (int, list, tuple): Number of features in the input, matches channels\n",
        "                                         in conv layers or features in linear layers. Can\n",
        "                                         be a single integer or a list/tuple for complex scenarios.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_features):\n",
        "        super(BNL, self).__init__()\n",
        "        # Check if num_features is a list or tuple, convert if necessary\n",
        "        if isinstance(num_features, int):\n",
        "            num_features = (num_features,)\n",
        "\n",
        "        self.num_features = num_features\n",
        "        self.weight = nn.Parameter(torch.ones(num_features))\n",
        "        self.bias = nn.Parameter(torch.zeros(num_features))\n",
        "        self.eps = 1e-5\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(self.num_features) == 1:  # Traditional usage like BatchNorm\n",
        "            mean = x.mean([0, 2, 3], keepdim=True) if x.dim() == 4 else x.mean(0, keepdim=True)\n",
        "            var = x.var([0, 2, 3], keepdim=True) if x.dim() == 4 else x.var(0, keepdim=True)\n",
        "            x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "            noise = torch.randn(self.weight.shape, device=x.device)\n",
        "            gamma_noisy = self.weight * (1 + noise)\n",
        "\n",
        "            if x.dim() == 4:\n",
        "                gamma_noisy = gamma_noisy.view(1, -1, 1, 1)\n",
        "                bias = self.bias.view(1, -1, 1, 1)\n",
        "            elif x.dim() == 2:\n",
        "                gamma_noisy = gamma_noisy.view(1, -1)\n",
        "                bias = self.bias.view(1, -1)\n",
        "\n",
        "            return gamma_noisy * x_normalized + bias\n",
        "        else:  # LayerNorm-like usage\n",
        "            mean = x.mean(dim=tuple(range(x.dim())[1:]), keepdim=True)\n",
        "            var = x.var(dim=tuple(range(x.dim())[1:]), keepdim=True, unbiased=False)\n",
        "            x_normalized = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "            noise = torch.randn(self.weight.shape, device=x.device)\n",
        "            gamma_noisy = self.weight * (1 + noise)\n",
        "\n",
        "            weight = self.weight.view((1,) + self.num_features + (1,) * (x.dim() - len(self.num_features) - 1))\n",
        "            bias = self.bias.view((1,) + self.num_features + (1,) * (x.dim() - len(self.num_features) - 1))\n",
        "\n",
        "            return gamma_noisy * x_normalized + bias"
      ],
      "metadata": {
        "id": "BIXSRCA8PQ_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ABNNLoss(torch.nn.Module):\n",
        "    def __init__(self, Num_classes, model_parameters, Weight_decay=1e-4):\n",
        "        super(ABNNLoss, self).__init__()\n",
        "        self.model_parameters = model_parameters\n",
        "        self.Weight_decay = Weight_decay\n",
        "        self.eta = nn.Parameter(torch.ones(Num_classes))\n",
        "\n",
        "    def forward(self, outputs, labels):\n",
        "        # Calculate the three loss components\n",
        "        nll_loss = self.negative_log_likelihood(outputs, labels)\n",
        "        log_prior_loss = self.negative_log_prior(self.model_parameters, self.Weight_decay)\n",
        "        custom_ce_loss = self.custom_cross_entropy_loss(outputs, labels, self.eta)\n",
        "\n",
        "        # Sum up all three components to form the ABNN loss\n",
        "        total_loss = nll_loss + log_prior_loss + custom_ce_loss\n",
        "        return total_loss\n",
        "\n",
        "    @staticmethod\n",
        "    def negative_log_likelihood(outputs, labels):\n",
        "        # Negative Log Likelihood (NLL) or MLE Loss:\n",
        "        # NLL = -∑ log P(y_i | x_i, ω)\n",
        "        return torch.nn.functional.cross_entropy(outputs, labels)\n",
        "\n",
        "    def negative_log_prior(self, model_parameters, Weight_decay=1e-4):\n",
        "        # Negative Log Prior with Gaussian Prior (L2 Regularization):\n",
        "        # log P(ω) = λ ∑ ω^2 where λ (weight decay) = (1/2σ^2)\n",
        "        l2_reg = sum(p.pow(2).sum() for p in model_parameters)\n",
        "        return Weight_decay * l2_reg\n",
        "\n",
        "    def custom_cross_entropy_loss(self, outputs, labels, eta):\n",
        "        # Custom Cross-Entropy Loss:\n",
        "        # E(ω) = -∑ η_i log P(y_i | x_i, ω)\n",
        "        log_probs = torch.nn.functional.log_softmax(outputs, dim=1)\n",
        "        weighted_log_probs = eta[labels] * log_probs.gather(1, labels.unsqueeze(1)).squeeze(1)\n",
        "        return -torch.mean(weighted_log_probs)"
      ],
      "metadata": {
        "id": "LX4A4yc0PVYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSIL3-JpPu3C",
        "outputId": "536ae689-264a-4162-9484-256344d36f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            planes, self.expansion * planes, kernel_size=1, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=100):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())\n",
        "\n",
        "\n",
        "def resnet18_imagenet(pretrained=False, classes=10):\n",
        "    model = torchvision.models.resnet18(pretrained=pretrained, num_classes=1000)\n",
        "    model.conv1 = nn.Conv2d(\n",
        "        3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
        "    )\n",
        "    model.maxpool = nn.Identity()\n",
        "    model.fc = nn.Linear(512, classes, bias=True)\n",
        "    return model\n",
        "\n",
        "def resnet50_imagenet(pretrained=False, classes=10):\n",
        "    model = torchvision.models.resnet50(pretrained=pretrained, num_classes=1000)\n",
        "    model.fc = nn.Linear(512, classes, bias=True)\n",
        "    return model"
      ],
      "metadata": {
        "id": "SL6ip_mJP-PQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BNLBasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BNLBasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = BNL(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = BNL(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                BNL(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            planes, self.expansion * planes, kernel_size=1, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class BNLResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=100):\n",
        "        super(BNLResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = BNL(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def BNLResNet18():\n",
        "    return BNLResNet(BNLBasicBlock, [2, 2, 2, 2])"
      ],
      "metadata": {
        "id": "ukX_JcahUpwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"ResNet in PyTorch.\n",
        "For Pre-activation ResNet, see 'preact_resnet.py'.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=1, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes, planes, kernel_size=3, stride=stride, padding=1, bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            planes, self.expansion * planes, kernel_size=1, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion * planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    in_planes,\n",
        "                    self.expansion * planes,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False,\n",
        "                ),\n",
        "                nn.BatchNorm2d(self.expansion * planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=100):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1] * (num_blocks - 1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])"
      ],
      "metadata": {
        "id": "uoS6-NSRURLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_167.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model5 = ResNet18()\n",
        "model5.load_state_dict(filtered_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Ct-9rq5ZRFv9",
        "outputId": "3ee4728d-815b-447a-fca7-d5eb1a1d188d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'epoch_167.ckpt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-c5e74c766296>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Load the checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch_167.ckpt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Extract and fix the state_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'epoch_167.ckpt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = ABNNLoss(100, model5.parameters()).to(device)\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model5.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "8kHGLN0qRKUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2Ehr_dyWNb-",
        "outputId": "78d0602a-4f67-4278-86f3-bca407aec03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BNLResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BNL()\n",
              "  (layer1): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BNL()\n",
              "      )\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BNL()\n",
              "      )\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BNLBasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BNL()\n",
              "      )\n",
              "    )\n",
              "    (1): BNLBasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BNL()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BNL()\n",
              "      (shortcut): Sequential()\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "print('Start Training')\n",
        "\n",
        "# Timing the training process\n",
        "start_time = time.time()\n",
        "\n",
        "# List to store loss values\n",
        "train_losses = []\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        eta = torch.rand(labels.size(0), device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model5(inputs)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "    print(f'[Epoch {epoch + 1}, Loss: {running_loss}')\n",
        "    running_loss = 0.0\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print('Finished Training')\n",
        "print(f'Time taken to train the model: {end_time - start_time:.2f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGeXCPeMVuRr",
        "outputId": "d4de160f-067b-4aa9-a876-e2b33291c005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training\n",
            "[Epoch 1, Loss: 2517.9910378456116\n",
            "[Epoch 2, Loss: 1976.281992673874\n",
            "[Epoch 3, Loss: 1849.281532049179\n",
            "[Epoch 4, Loss: 1774.8414433002472\n",
            "[Epoch 5, Loss: 1747.916981935501\n",
            "[Epoch 6, Loss: 1709.4862475395203\n",
            "[Epoch 7, Loss: 1681.392540693283\n",
            "[Epoch 8, Loss: 1655.3081946372986\n",
            "[Epoch 9, Loss: 1640.1109764575958\n",
            "[Epoch 10, Loss: 1625.9923396110535\n",
            "[Epoch 11, Loss: 1618.76971077919\n",
            "[Epoch 12, Loss: 1593.5048666000366\n",
            "[Epoch 13, Loss: 1586.5120894908905\n",
            "[Epoch 14, Loss: 1565.612500667572\n",
            "[Epoch 15, Loss: 1562.6503715515137\n",
            "[Epoch 16, Loss: 1555.6033828258514\n",
            "[Epoch 17, Loss: 1551.3173110485077\n",
            "[Epoch 18, Loss: 1544.7979979515076\n",
            "[Epoch 19, Loss: 1527.7255206108093\n",
            "[Epoch 20, Loss: 1524.6597218513489\n",
            "Finished Training\n",
            "Time taken to train the model: 1205.05 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "model5.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = model5(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBgPFAxdVwwe",
        "outputId": "97cdd277-88a2-4099-97db-0df21f46dcff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 58.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5.eval()\n",
        "all_probs = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model5(inputs)  # logits\n",
        "        probs = torch.softmax(outputs, dim=1)  # convert logits to probabilities\n",
        "\n",
        "        all_probs.append(probs)\n",
        "        true_labels.append(labels)\n",
        "\n",
        "# Concatenate everything\n",
        "all_probs = torch.cat(all_probs, dim=0)            # Shape: [N, C]\n",
        "true_labels = torch.cat(true_labels, dim=0)"
      ],
      "metadata": {
        "id": "Ka4VBqkDX_iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Use log probabilities for NLL\n",
        "log_probs = torch.log(all_probs + 1e-12)  # for numerical stability\n",
        "\n",
        "# Compute Negative Log-Likelihood\n",
        "nll = F.nll_loss(log_probs, true_labels)\n",
        "print(f\"NLL (Single Model): {nll:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BMVfTcmYBLM",
        "outputId": "597e7941-fd28-433f-8705-74711dfa7514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLL (Single Model): 2.1098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model5.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': running_loss,\n",
        "}, 'bnn100.ckpt')"
      ],
      "metadata": {
        "id": "v-W9rA39YDS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4bNRFhRvYFHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pYcizj8zYIRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_172.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "#filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model6 = ResNet18()\n",
        "model6.load_state_dict(new_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSvaUt2oYIKp",
        "outputId": "82a5c7f7-e934-4454-def0-f17499aae75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "48ZxVUhbgfni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model6.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "1fL2mKkbaWMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "model6.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = model6(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "OxvnWsbsYKz-",
        "outputId": "5c8d0ceb-5289-4c5b-b5a8-a328419530cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f46aa9feb93d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-56215f97edf9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model6.eval()\n",
        "all_probs = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model6(inputs)  # logits\n",
        "        probs = torch.softmax(outputs, dim=1)  # convert logits to probabilities\n",
        "\n",
        "        all_probs.append(probs)\n",
        "        true_labels.append(labels)\n",
        "\n",
        "# Concatenate everything\n",
        "all_probs = torch.cat(all_probs, dim=0)            # Shape: [N, C]\n",
        "true_labels = torch.cat(true_labels, dim=0)"
      ],
      "metadata": {
        "id": "Qs_rUGIlYNDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Use log probabilities for NLL\n",
        "log_probs = torch.log(all_probs + 1e-12)  # for numerical stability\n",
        "\n",
        "# Compute Negative Log-Likelihood\n",
        "nll = F.nll_loss(log_probs, true_labels)\n",
        "print(f\"NLL (Single Model): {nll:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFJ_66QkYPE2",
        "outputId": "b8b07ec1-ceda-4e1a-a6bb-bc817f58298d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLL (Single Model): 1.7997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZCeJwZjrYRG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_172.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model7 = BNLResNet18()\n",
        "model7.load_state_dict(filtered_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll3wtBIHZjX1",
        "outputId": "d3637a41-e51d-4c34-e970-d726295d675d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7.to(device)\n",
        "loss_func = ABNNLoss(100, model7.parameters()).to(device)\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model7.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "SRaUYjoMZjM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('Start Training')\n",
        "\n",
        "# Timing the training process\n",
        "start_time = time.time()\n",
        "\n",
        "# List to store loss values\n",
        "train_losses = []\n",
        "for epoch in range(20):\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)\n",
        "        eta = torch.rand(labels.size(0), device=device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model7(inputs)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        train_losses.append(loss.item())\n",
        "    print(f'[Epoch {epoch + 1}, Loss: {running_loss}')\n",
        "    running_loss = 0.0\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print('Finished Training')\n",
        "print(f'Time taken to train the model: {end_time - start_time:.2f} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "Nhif408qZmaT",
        "outputId": "2d7e268f-f7c4-494d-9526-a163467566a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-78b861d20a73>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'[Epoch {epoch + 1}, Loss: {running_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure the model is in evaluation mode\n",
        "model7.eval()\n",
        "\n",
        "# Variables to track the correct predictions and total predictions\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Ensure no gradients are calculated as we are only making predictions\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "        # Collect predictions from multiple evaluations\n",
        "        predictions = []\n",
        "        for _ in range(50):\n",
        "            outputs = model7(images)\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            predictions.append(preds)\n",
        "\n",
        "        # Calculate the mode of the predictions\n",
        "        predictions = torch.stack(predictions)\n",
        "        predicted, _ = torch.mode(predictions, dim=0)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the test images: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMDtjU-uZpGJ",
        "outputId": "984dfd0c-8f87-4781-84fe-d2981d064ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 43.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model7.eval()\n",
        "all_probs = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model7(inputs)  # logits\n",
        "        probs = torch.softmax(outputs, dim=1)  # convert logits to probabilities\n",
        "\n",
        "        all_probs.append(probs)\n",
        "        true_labels.append(labels)\n",
        "\n",
        "# Concatenate everything\n",
        "all_probs = torch.cat(all_probs, dim=0)            # Shape: [N, C]\n",
        "true_labels = torch.cat(true_labels, dim=0)"
      ],
      "metadata": {
        "id": "Qu4FOo-nZrYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Use log probabilities for NLL\n",
        "log_probs = torch.log(all_probs + 1e-12)  # for numerical stability\n",
        "\n",
        "# Compute Negative Log-Likelihood\n",
        "nll = F.nll_loss(log_probs, true_labels)\n",
        "print(f\"NLL (Single Model): {nll:.4f}\")\n"
      ],
      "metadata": {
        "id": "hemmbb1vZtWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce0929b6-9c94-4df5-e511-8a3a298f2654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLL (Single Model): 4.0751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'model_state_dict': model7.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': running_loss,\n",
        "}, 'rhoabnn100.ckpt')"
      ],
      "metadata": {
        "id": "WuvmMDL4ZvE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDropE1Aqx8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Define a function to set seeds for reproducibility\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "# Train one instance of the model\n",
        "def train_one_instance(model_id, trainloader, device, loss_func, num_epochs=20):\n",
        "    print(f\"Training model {model_id}\")\n",
        "\n",
        "    set_seed(42 + model_id)  # Different seed for each instance\n",
        "\n",
        "    model = BNLResNet18().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    model.train()\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_losses = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "            eta = torch.rand(labels.size(0), device=device)  # Unused here?\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_func(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "        print(f'[Model {model_id}, Epoch {epoch + 1}] Loss: {running_loss:.4f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f'Model {model_id} Finished Training in {end_time - start_time:.2f} seconds')\n",
        "\n",
        "    # Save the model\n",
        "    torch.save(model.state_dict(), f\"bnlresnet18_instance_{model_id}.pth\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "9tcnBu2NqyU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def ensemble_predict(models, dataloader, device):\n",
        "    all_outputs = []\n",
        "\n",
        "    for model in models:\n",
        "        model.eval()\n",
        "        outputs = []\n",
        "        with torch.no_grad():\n",
        "            for data in dataloader:\n",
        "                inputs, _ = data\n",
        "                inputs = inputs.to(device)\n",
        "                output = torch.softmax(model(inputs), dim=1)  # probability outputs\n",
        "                outputs.append(output.cpu())\n",
        "        all_outputs.append(torch.cat(outputs))\n",
        "\n",
        "    # Average predictions\n",
        "    ensemble_output = torch.mean(torch.stack(all_outputs), dim=0)\n",
        "    return ensemble_output"
      ],
      "metadata": {
        "id": "cfvTf2Opq6bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd RHO-Loss/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPFCn6ZxsEtO",
        "outputId": "cf072bbc-6a07-4295-bcd3-4a3a1290a479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'RHO-Loss/'\n",
            "/content/RHO-Loss\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Load the checkpoint\n",
        "ckpt = torch.load(\"epoch_172.ckpt\", map_location=\"cpu\",weights_only=False)\n",
        "\n",
        "# Extract and fix the state_dict\n",
        "state_dict = ckpt[\"state_dict\"]\n",
        "new_state_dict = {}\n",
        "\n",
        "# Strip \"large_model.\" from the keys\n",
        "for key in state_dict:\n",
        "    new_key = key.replace(\"large_model.\", \"\")\n",
        "    new_state_dict[new_key] = state_dict[key]\n",
        "\n",
        "# Load into your model\n",
        "filtered_state_dict = {k: v for k, v in new_state_dict.items() if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k}\n",
        "model = BNLResNet18()\n",
        "model.load_state_dict(filtered_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLZeaJG8r8HZ",
        "outputId": "c10083f8-987e-4f21-ee74-85c12d5d6ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = ABNNLoss(100, model.parameters()).to(device)\n",
        "optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0057, momentum=0.9, weight_decay=5e-4)\n"
      ],
      "metadata": {
        "id": "8bF1R_pLq_Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train 4 instances\n",
        "models = []\n",
        "for i in range(4):\n",
        "    model = train_one_instance(i, trainloader, device, loss_func)\n",
        "    models.append(model)\n",
        "\n",
        "# Perform ensemble inference\n",
        "ensemble_probs = ensemble_predict(models, testloader, device)\n",
        "\n",
        "# If you want hard labels:\n",
        "ensemble_preds = torch.argmax(ensemble_probs, dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-heFcg4ZyvK",
        "outputId": "c3cc40e4-9ef1-4285-cb9f-2183204d1863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model 0\n",
            "[Model 0, Epoch 1] Loss: 3398.3284\n",
            "[Model 0, Epoch 2] Loss: 3041.9074\n",
            "[Model 0, Epoch 3] Loss: 2861.1012\n",
            "[Model 0, Epoch 4] Loss: 2703.1394\n",
            "[Model 0, Epoch 5] Loss: 2570.7232\n",
            "[Model 0, Epoch 6] Loss: 2465.6284\n",
            "[Model 0, Epoch 7] Loss: 2373.3586\n",
            "[Model 0, Epoch 8] Loss: 2288.6973\n",
            "[Model 0, Epoch 9] Loss: 2202.8708\n",
            "[Model 0, Epoch 10] Loss: 2118.3165\n",
            "[Model 0, Epoch 11] Loss: 2052.9063\n",
            "[Model 0, Epoch 12] Loss: 1983.9764\n",
            "[Model 0, Epoch 13] Loss: 1914.9001\n",
            "[Model 0, Epoch 14] Loss: 1856.4559\n",
            "[Model 0, Epoch 15] Loss: 1802.3951\n",
            "[Model 0, Epoch 16] Loss: 1762.2225\n",
            "[Model 0, Epoch 17] Loss: 1712.2112\n",
            "[Model 0, Epoch 18] Loss: 1675.2091\n",
            "[Model 0, Epoch 19] Loss: 1647.1781\n",
            "[Model 0, Epoch 20] Loss: 1618.6209\n",
            "Model 0 Finished Training in 1204.83 seconds\n",
            "Training model 1\n",
            "[Model 1, Epoch 1] Loss: 3369.0899\n",
            "[Model 1, Epoch 2] Loss: 3058.2545\n",
            "[Model 1, Epoch 3] Loss: 2874.8103\n",
            "[Model 1, Epoch 4] Loss: 2729.5507\n",
            "[Model 1, Epoch 5] Loss: 2597.7319\n",
            "[Model 1, Epoch 6] Loss: 2496.2852\n",
            "[Model 1, Epoch 7] Loss: 2395.2327\n",
            "[Model 1, Epoch 8] Loss: 2304.7074\n",
            "[Model 1, Epoch 9] Loss: 2220.5109\n",
            "[Model 1, Epoch 10] Loss: 2133.1803\n",
            "[Model 1, Epoch 11] Loss: 2056.9277\n",
            "[Model 1, Epoch 12] Loss: 1993.1246\n",
            "[Model 1, Epoch 13] Loss: 1934.6101\n",
            "[Model 1, Epoch 14] Loss: 1872.5318\n",
            "[Model 1, Epoch 15] Loss: 1832.2722\n",
            "[Model 1, Epoch 16] Loss: 1780.7420\n",
            "[Model 1, Epoch 17] Loss: 1740.1239\n",
            "[Model 1, Epoch 18] Loss: 1712.4270\n",
            "[Model 1, Epoch 19] Loss: 1660.9794\n",
            "[Model 1, Epoch 20] Loss: 1631.0920\n",
            "Model 1 Finished Training in 1203.34 seconds\n",
            "Training model 2\n",
            "[Model 2, Epoch 1] Loss: 3398.5114\n",
            "[Model 2, Epoch 2] Loss: 3055.4534\n",
            "[Model 2, Epoch 3] Loss: 2862.9172\n",
            "[Model 2, Epoch 4] Loss: 2703.4295\n",
            "[Model 2, Epoch 5] Loss: 2583.2770\n",
            "[Model 2, Epoch 6] Loss: 2475.0015\n",
            "[Model 2, Epoch 7] Loss: 2382.7010\n",
            "[Model 2, Epoch 8] Loss: 2301.0252\n",
            "[Model 2, Epoch 9] Loss: 2207.0937\n",
            "[Model 2, Epoch 10] Loss: 2128.3309\n",
            "[Model 2, Epoch 11] Loss: 2044.3087\n",
            "[Model 2, Epoch 12] Loss: 1984.1604\n",
            "[Model 2, Epoch 13] Loss: 1926.0109\n",
            "[Model 2, Epoch 14] Loss: 1863.3277\n",
            "[Model 2, Epoch 15] Loss: 1803.0961\n",
            "[Model 2, Epoch 16] Loss: 1767.6327\n",
            "[Model 2, Epoch 17] Loss: 1728.8880\n",
            "[Model 2, Epoch 18] Loss: 1685.1896\n",
            "[Model 2, Epoch 19] Loss: 1645.5193\n",
            "[Model 2, Epoch 20] Loss: 1615.0062\n",
            "Model 2 Finished Training in 1203.58 seconds\n",
            "Training model 3\n",
            "[Model 3, Epoch 1] Loss: 3414.3011\n",
            "[Model 3, Epoch 2] Loss: 3062.1620\n",
            "[Model 3, Epoch 3] Loss: 2880.0380\n",
            "[Model 3, Epoch 4] Loss: 2721.5654\n",
            "[Model 3, Epoch 5] Loss: 2587.2355\n",
            "[Model 3, Epoch 6] Loss: 2476.8858\n",
            "[Model 3, Epoch 7] Loss: 2371.6359\n",
            "[Model 3, Epoch 8] Loss: 2274.1954\n",
            "[Model 3, Epoch 9] Loss: 2185.4542\n",
            "[Model 3, Epoch 10] Loss: 2094.8450\n",
            "[Model 3, Epoch 11] Loss: 2016.8166\n",
            "[Model 3, Epoch 12] Loss: 1948.2852\n",
            "[Model 3, Epoch 13] Loss: 1887.7923\n",
            "[Model 3, Epoch 14] Loss: 1828.7748\n",
            "[Model 3, Epoch 15] Loss: 1786.8103\n",
            "[Model 3, Epoch 16] Loss: 1744.1844\n",
            "[Model 3, Epoch 17] Loss: 1706.9300\n",
            "[Model 3, Epoch 18] Loss: 1671.6100\n",
            "[Model 3, Epoch 19] Loss: 1639.1768\n",
            "[Model 3, Epoch 20] Loss: 1609.0135\n",
            "Model 3 Finished Training in 1203.98 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_NLL(probs, labels):\n",
        "    \"\"\"\n",
        "    probs: tensor of shape (N, C) - ensemble probabilities (after softmax and averaging)\n",
        "    labels: tensor of shape (N,) - ground truth labels\n",
        "    \"\"\"\n",
        "    # Use log probabilities and gather only for correct classes\n",
        "    log_probs = torch.log(probs + 1e-12)  # avoid log(0)\n",
        "    nll = F.nll_loss(log_probs, labels, reduction='mean')\n",
        "    return nll.item()"
      ],
      "metadata": {
        "id": "kMsKa8MLrK7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get true labels from testloader\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        true_labels.extend(labels)\n",
        "\n",
        "# Convert to a torch tensor\n",
        "true_labels = torch.tensor(true_labels, dtype=torch.long, device=ensemble_probs.device)"
      ],
      "metadata": {
        "id": "7HUZSypQ9M9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `ensemble_probs` is of shape [N, C] and already averaged over ensemble members\n",
        "# And `true_labels` is a 1D tensor of length N\n",
        "\n",
        "nll = compute_NLL(ensemble_probs, true_labels)\n",
        "print(f\"NLL (Ensemble): {nll:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyv6lILG9QGU",
        "outputId": "335d2eaa-af20-495a-a42b-3168c760a76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLL (Ensemble): 1.9288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xp8g0CrT9SmF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}